{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheLegendVilva/ModelProjects/blob/main/MisaHubResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classifying Bleeding and Non-Bleeding Using Resnet**"
      ],
      "metadata": {
        "id": "4PkpgiAcFLLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing and Splitting**\n"
      ],
      "metadata": {
        "id": "r89LWZP2g9GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoJ-HvHoeo0Q",
        "outputId": "564f2d49-69fa-4888-b7ef-32104fe18d1c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/drive/MyDrive/WCEBleedGen.zip'\n",
        "!unzip $zip_path -d MISAHUB"
      ],
      "metadata": {
        "id": "f4wAqXaHepk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "images_folder = '/content/MISAHUB/WCEBleedGen/bleeding/Images'\n",
        "annotations_folder = '/content/MISAHUB/WCEBleedGen/bleeding/Bounding boxes/YOLO_TXT'\n",
        "output_folder = '/content/MISAHUB/train/'\n",
        "\n",
        "# Create the 'train' folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Create 'images' and 'labels' folders inside 'train'\n",
        "images_output_folder = os.path.join(output_folder, 'images')\n",
        "labels_output_folder = os.path.join(output_folder, 'labels')\n",
        "\n",
        "os.makedirs(images_output_folder, exist_ok=True)\n",
        "os.makedirs(labels_output_folder, exist_ok=True)\n",
        "\n",
        "# Get a list of files in both folders\n",
        "image_files = os.listdir(images_folder)\n",
        "annotation_files = os.listdir(annotations_folder)\n",
        "\n",
        "# Ensure only files with the same base name are considered\n",
        "image_files = [file for file in image_files if file.endswith('.png')]\n",
        "annotation_files = [file for file in annotation_files if file.endswith('.txt')]\n",
        "\n",
        "# Sort the files to ensure consistent numbering\n",
        "image_files.sort()\n",
        "annotation_files.sort()\n",
        "\n",
        "# Rename and move the files to the 'train' folder\n",
        "for i, (image_file, annotation_file) in enumerate(zip(image_files, annotation_files), start=1):\n",
        "    # Define the new names for the image and annotation\n",
        "    new_image_name = f\"image_{i}.png\"\n",
        "    new_annotation_name = f\"image_{i}.txt\"\n",
        "\n",
        "    # Rename and move the image file\n",
        "    old_image_path = os.path.join(images_folder, image_file)\n",
        "    new_image_path = os.path.join(images_output_folder, new_image_name)\n",
        "    os.rename(old_image_path, new_image_path)\n",
        "\n",
        "    # Rename and move the annotation file\n",
        "    old_annotation_path = os.path.join(annotations_folder, annotation_file)\n",
        "    new_annotation_path = os.path.join(labels_output_folder, new_annotation_name)\n",
        "    os.rename(old_annotation_path, new_annotation_path)\n",
        "\n",
        "    print(f\"Renamed and moved: {image_file} to {new_image_name}\")\n",
        "    print(f\"Renamed and moved: {annotation_file} to {new_annotation_name}\")\n",
        "\n",
        "print(\"All files have been renamed and moved to the 'train' folder.\")\n"
      ],
      "metadata": {
        "id": "Wc8Sl_fUfP1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "images_folder = '/content/MISAHUB/WCEBleedGen/non-bleeding/images'\n",
        "output_folder = '/content/MISAHUB/train/'\n",
        "\n",
        "# Create the 'train' folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Create 'images' and 'labels' folders inside 'train'\n",
        "images_output_folder = os.path.join(output_folder, 'images')\n",
        "labels_output_folder = os.path.join(output_folder, 'labels')\n",
        "\n",
        "os.makedirs(images_output_folder, exist_ok=True)\n",
        "os.makedirs(labels_output_folder, exist_ok=True)\n",
        "\n",
        "# Get a list of files in the 'images' folder\n",
        "image_files = os.listdir(images_folder)\n",
        "image_files = [file for file in image_files if file.endswith('.png')]\n",
        "image_files.sort()\n",
        "\n",
        "# Rename and move the files to the 'train' folder\n",
        "for i, image_file in enumerate(image_files, start=1310):\n",
        "    # Define the new names for the image and annotation\n",
        "    new_image_name = f\"images_{i}.png\"\n",
        "    new_annotation_name = f\"images_{i}.txt\"\n",
        "\n",
        "    # Rename and move the image file\n",
        "    old_image_path = os.path.join(images_folder, image_file)\n",
        "    new_image_path = os.path.join(images_output_folder, new_image_name)\n",
        "    os.rename(old_image_path, new_image_path)\n",
        "\n",
        "    # Create an empty label file in the 'labels' folder\n",
        "    new_annotation_path = os.path.join(labels_output_folder, new_annotation_name)\n",
        "    with open(new_annotation_path, 'w') as empty_file:\n",
        "        pass\n",
        "\n",
        "    print(f\"Renamed and moved: {image_file} to {new_image_name}\")\n",
        "    print(f\"Created empty label file: {new_annotation_name}\")\n",
        "\n",
        "print(\"All files have been renamed and moved to the 'train' folder.\")"
      ],
      "metadata": {
        "id": "ukgpuDXAVy3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the paths to the 'train' directory and its subdirectories\n",
        "train_dir = 'MISAHUB/train'  # Update this with the actual path to your 'train' directory\n",
        "images_dir = os.path.join(train_dir, 'images')\n",
        "labels_dir = os.path.join(train_dir, 'labels')\n",
        "train_dir = 'MISAHUB/newTrain'\n",
        "# Create output directories for the two classes\n",
        "bleeding_dir = os.path.join(train_dir, 'bleeding')\n",
        "non_bleeding_dir = os.path.join(train_dir, 'non_bleeding')\n",
        "\n",
        "# Create the 'bleeding' and 'non_bleeding' directories if they don't exist\n",
        "os.makedirs(bleeding_dir, exist_ok=True)\n",
        "os.makedirs(non_bleeding_dir, exist_ok=True)\n",
        "\n",
        "# Iterate through the files in the 'images' directory\n",
        "for image_filename in os.listdir(images_dir):\n",
        "    # Form the corresponding label file path\n",
        "    label_filename = os.path.splitext(image_filename)[0] + '.txt'\n",
        "    label_filepath = os.path.join(labels_dir, label_filename)\n",
        "\n",
        "    # Check if the label file is empty (indicating non-bleeding)\n",
        "    if os.path.exists(label_filepath) and os.path.getsize(label_filepath) == 0:\n",
        "        # Move the image to the 'non_bleeding' directory\n",
        "        shutil.move(os.path.join(images_dir, image_filename), os.path.join(non_bleeding_dir, image_filename))\n",
        "    else:\n",
        "        # Move the image to the 'bleeding' directory\n",
        "        shutil.move(os.path.join(images_dir, image_filename), os.path.join(bleeding_dir, image_filename))\n",
        "\n",
        "print(\"Dataset organized into 'bleeding' and 'non_bleeding' classes.\")\n"
      ],
      "metadata": {
        "id": "mm2rQtsDWwP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a6eba8-9532-4d82-882b-7bef56dcd910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset organized into 'bleeding' and 'non_bleeding' classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls MISAHUB/newTrain/bleeding | wc -l"
      ],
      "metadata": {
        "id": "UavS7_rSVe87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac303bd-68d3-42c4-98d7-f1a96cba4e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Define the paths to the 'bleeding' and 'non_bleeding' directories\n",
        "bleeding_dir = '/content/MISAHUB/newTrain/bleeding'  # Update with the actual path to your 'bleeding' directory\n",
        "non_bleeding_dir = '/content/MISAHUB/newTrain/non_bleeding'  # Update with the actual path to your 'non-bleeding' directory\n",
        "\n",
        "# Define the path to the 'test' directory\n",
        "test_dir = '/content/MISAHUB/test'  # Update with the path where you want to create the 'test' directory\n",
        "\n",
        "# Create the 'test' directory if it doesn't exist\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Define the number of files to randomly select from each directory\n",
        "num_files_to_select = 20\n",
        "\n",
        "# Randomly select 20 files from the 'bleeding' directory\n",
        "bleeding_files = os.listdir(bleeding_dir)\n",
        "selected_bleeding_files = random.sample(bleeding_files, num_files_to_select)\n",
        "\n",
        "# Randomly select 20 files from the 'non_bleeding' directory\n",
        "non_bleeding_files = os.listdir(non_bleeding_dir)\n",
        "selected_non_bleeding_files = random.sample(non_bleeding_files, num_files_to_select)\n",
        "\n",
        "# Copy the selected 'bleeding' files to the 'test' directory with new names\n",
        "for filename in selected_bleeding_files:\n",
        "    source_filepath = os.path.join(bleeding_dir, filename)\n",
        "    new_filename = f'bleeding_{filename}'\n",
        "    dest_filepath = os.path.join(test_dir, new_filename)\n",
        "    shutil.copy(source_filepath, dest_filepath)\n",
        "    # Remove the file from the 'bleeding' directory\n",
        "    os.remove(source_filepath)\n",
        "\n",
        "# Copy the selected 'non_bleeding' files to the 'test' directory with new names\n",
        "for filename in selected_non_bleeding_files:\n",
        "    source_filepath = os.path.join(non_bleeding_dir, filename)\n",
        "    new_filename = f'non_bleeding_{filename}'\n",
        "    dest_filepath = os.path.join(test_dir, new_filename)\n",
        "    shutil.copy(source_filepath, dest_filepath)\n",
        "    # Remove the file from the 'non_bleeding' directory\n",
        "    os.remove(source_filepath)\n",
        "\n",
        "print(f\"Selected and copied {num_files_to_select} files from 'bleeding' and 'non-bleeding' to the 'test' directory, and removed them from the original directories.\")\n"
      ],
      "metadata": {
        "id": "rq7U71RIWwRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "0gSmVvwUfp2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "dataset_dir = 'MISAHUB/newTrain'\n",
        "dataset_dir = Path(dataset_dir)\n",
        "bleeding = list(dataset_dir.glob('bleeding/*'))\n",
        "print(bleeding[0])\n",
        "image = PIL.Image.open(str(bleeding[0]))\n",
        "width, height = image.size\n",
        "print(width, height)"
      ],
      "metadata": {
        "id": "M6N5_xdqqz3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9aa84e4-5cd3-4b59-dcb1-31d4a2836f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MISAHUB/newTrain/bleeding/image_1030.png\n",
            "224 224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# Define the path to the 'train' directory\n",
        "train_dir = 'MISAHUB/newTrain'\n",
        "img_height,img_width=224,224\n",
        "batch_size=32\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    batch_size=32,  # Adjust batch size as needed\n",
        "    image_size=(224, 224),  # Specify the desired image size\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=0.2,  # Split a portion of data for validation\n",
        "    subset='training'  # Use 'training' subset for training data\n",
        ")\n",
        "\n",
        "# Create the validation dataset with the same validation split\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    batch_size=32,  # Adjust batch size as needed\n",
        "    image_size=(224, 224),  # Specify the desired image size\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=0.2,  # Use the same validation split as for training\n",
        "    subset='validation'  # Use 'validation' subset for validation data\n",
        ")"
      ],
      "metadata": {
        "id": "IitcVWIWqrzv",
        "outputId": "02ce1634-8a5a-492c-8c55-e9475eaeae9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2578 files belonging to 2 classes.\n",
            "Using 2063 files for training.\n",
            "Found 2578 files belonging to 2 classes.\n",
            "Using 515 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_dataset.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "hz3H4ykAsZLv",
        "outputId": "e27c7f9f-b286-4508-88bc-e0d79e8094d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bleeding', 'non_bleeding']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Classification ResNet**"
      ],
      "metadata": {
        "id": "AewhITJMgvWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "resnet_model = Sequential()\n",
        "\n",
        "pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "                   input_shape=(224,224,3),\n",
        "                   pooling='max',classes=2,\n",
        "                   weights='imagenet')\n",
        "# for layer in pretrained_model.layers:\n",
        "#         layer.trainable=False\n",
        "# Unfreeze specific layers\n",
        "for layer in pretrained_model.layers:\n",
        "    if layer.name in ['block4_conv1', 'block4_conv2', 'block4_conv3']:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "# Compile the model after unfreezing layers\n",
        "# resnet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.02)))\n",
        "resnet_model.add(Dropout(0.5))\n",
        "resnet_model.add(Dense(1, activation='sigmoid',kernel_regularizer=l2(0.02)))"
      ],
      "metadata": {
        "id": "PiWWXwTa0hAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c92c60d-6eb5-45f2-a946-f705fb3b3fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ocxlltpa09LS",
        "outputId": "5a0d7bbb-cc00-4984-b8ae-2c219201e728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " module_wrapper (ModuleWrap  (None, 2048)              0         \n",
            " per)                                                            \n",
            "                                                                 \n",
            " module_wrapper_1 (ModuleWr  (None, 512)               1049088   \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_2 (ModuleWr  (None, 512)               0         \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_3 (ModuleWr  (None, 1)                 513       \n",
            " apper)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24637313 (93.98 MB)\n",
            "Trainable params: 1049601 (4.00 MB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "EKycvVcE1A7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=5\n",
        "history = resnet_model.fit(\n",
        "  train_dataset,\n",
        "  validation_data=validation_dataset,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "8ZU2ADPF1Oic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the 'test' directory\n",
        "test_dir = 'MISAHUB/test'  # Update with the actual path to your 'test' directory\n",
        "\n",
        "# Get a list of all image files in the 'test' directory\n",
        "test_image_files = [os.path.join(test_dir, filename) for filename in os.listdir(test_dir)]\n",
        "\n",
        "# Iterate through the 'test' images\n",
        "for image_file in test_image_files:\n",
        "    # Load and preprocess the image\n",
        "    img = tf.keras.preprocessing.image.load_img(image_file, target_size=(224, 224))\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "\n",
        "    # Make predictions using the model\n",
        "    predictions = resnet_model.predict(img)\n",
        "\n",
        "    # Get the class label (assuming binary classification with 0 and 1)\n",
        "    class_label = \"bleeding\" if predictions[0][0] < 0.5 else \"non-bleeding\"\n",
        "\n",
        "    # Print the file name and predicted class\n",
        "    print(f\"File: {os.path.basename(image_file)}, Predicted Class: {class_label}\")\n"
      ],
      "metadata": {
        "id": "2oOoHdvTboRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating Model**"
      ],
      "metadata": {
        "id": "eSg6Sj0Y3RyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig1 = plt.gcf()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.axis(ymin=0.4,ymax=1)\n",
        "plt.grid()\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "NwjguSD73RMv",
        "outputId": "5a388d0d-f1c9-4328-805d-e5cd9058978f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the classifying Model:"
      ],
      "metadata": {
        "id": "QF7Nlo96A4QO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.save(\"/content/drive/My Drive/models/resnet_model_MISAHUB\")"
      ],
      "metadata": {
        "id": "DHMdcNA1A6qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detection on Bleeding Frames"
      ],
      "metadata": {
        "id": "QBg1qV4QBwFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "classifier = keras.models.load_model('/content/drive/My Drive/models/resnet_model_MISAHUB')"
      ],
      "metadata": {
        "id": "Dj0jgg2nB1MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will train the model for detection. For this we will use only the bleeding images and their annotations from the **MISAHUB/WCEBleedGen/bleeding** directory.</br>\n",
        "images: \"/content/MISAHUB/WCEBleedGen/bleeding/Images\"</br>\n",
        "bounding_boxes =  \"/content/MISAHUB/WCEBleedGen/bleeding/Bounding\\ boxes/XML\""
      ],
      "metadata": {
        "id": "uuTCxNzKClSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/drive/MyDrive/WCEBleedGen.zip'\n",
        "!unzip $zip_path -d MISAHUB"
      ],
      "metadata": {
        "id": "NjyoutgkCFQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPg_-ktuzVcp",
        "outputId": "4088334d-ddfb-4a6f-b16a-59d78f52d47b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Define the paths to the source directories\n",
        "images_dir = 'MISAHUB/WCEBleedGen/bleeding/Images'\n",
        "yolo_dir = 'MISAHUB/WCEBleedGen/bleeding/Bounding boxes/YOLO_TXT'\n",
        "\n",
        "# Define the paths for train, validation, and test directories\n",
        "train_dir = 'train_data'\n",
        "val_dir = 'val_data'\n",
        "test_dir = 'test_dir'\n",
        "\n",
        "# Create the train, validation, and test directories if they don't exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Define subdirectories for \"images\" and \"labels\"\n",
        "subdirs = ['images', 'labels']\n",
        "\n",
        "# Create subdirectories for train, validation, and test datasets\n",
        "for subdir in subdirs:\n",
        "    os.makedirs(os.path.join(train_dir, subdir), exist_ok=True)\n",
        "    os.makedirs(os.path.join(val_dir, subdir), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, subdir), exist_ok=True)\n",
        "\n",
        "\n",
        "# List all the image files\n",
        "image_files = os.listdir(images_dir)\n",
        "\n",
        "# Shuffle the files randomly\n",
        "random.shuffle(image_files)\n",
        "\n",
        "# Calculate the split sizes\n",
        "total_samples = len(image_files)\n",
        "train_size = int(0.7 * total_samples)\n",
        "val_size = int(0.295 * total_samples)\n",
        "test_size = int(0.05* total_samples)\n",
        "\n",
        "\n",
        "# Define a function to move image and XML files to the specified directory\n",
        "def move_files(source_dir, destination_dir, subdir, file_list):\n",
        "    for file_name in file_list:\n",
        "        source_path = os.path.join(source_dir, file_name)\n",
        "        destination_path = os.path.join(destination_dir, subdir, file_name)\n",
        "        shutil.copy(source_path, destination_path)\n",
        "\n",
        "# Move files to train directory\n",
        "move_files(images_dir, train_dir, 'images', image_files[:train_size])\n",
        "move_files(yolo_dir, train_dir, 'labels', [file.replace('.png', '.txt') for file in image_files[:train_size]])\n",
        "\n",
        "# Move files to validation directory\n",
        "move_files(images_dir, val_dir, 'images', image_files[train_size:train_size + val_size])\n",
        "move_files(yolo_dir, val_dir, 'labels', [file.replace('.png', '.txt') for file in image_files[train_size:train_size + val_size]])\n",
        "\n",
        "\n",
        "move_files(images_dir, test_dir, 'images', image_files[train_size:train_size + test_size])\n",
        "move_files(yolo_dir, test_dir, 'labels', [file.replace('.png', '.txt') for file in image_files[train_size:train_size + test_size]])\n",
        "\n"
      ],
      "metadata": {
        "id": "lP4okvjoF-8N"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yolov5\n"
      ],
      "metadata": {
        "id": "wuyAyZuwMXyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt  # install"
      ],
      "metadata": {
        "id": "dy3ExisXl9OX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce29160-7a72-4133-d5ca-e98bbb0b915d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "/content/yolov5\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.37)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.3)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.1)\n",
            "Requirement already satisfied: ultralytics>=8.0.147 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (8.0.195)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.43.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r requirements.txt (line 15)) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r requirements.txt (line 15)) (17.0.2)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.147->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3.post1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from utils.downloads import attempt_download  # to download models/datasets\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "metadata": {
        "id": "NQhIEocqnZ_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f44efda3-bbdd-464d-b63a-093bbf49d355"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 2.0.1+cu118 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15101MB, multi_processor_count=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!touch data.yaml"
      ],
      "metadata": {
        "id": "rZFZYdTpnmjV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fiRYCb7rKYH",
        "outputId": "a5a6ad3f-2768-488e-c313-ca84b0b35bc9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv train_data yolov5\n",
        "!mv val_data yolov5\n",
        "!mv test_dir yolov5"
      ],
      "metadata": {
        "id": "Uk9gU6senml3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5\n",
        "!python train.py --epochs 50 --data data.yaml --weights ../yolov5s.pt --cache"
      ],
      "metadata": {
        "id": "FlWVT2pKqVQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4154138-493b-4ccc-eee7-e3e63b77873d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../yolov5s.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 \n",
            "YOLOv5  v7.0-226-gdd9e338 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from ../yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/train_data/labels.cache... 916 images, 0 backgrounds, 0 corrupt: 100% 916/916 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB ram): 100% 916/916 [00:02<00:00, 305.51it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/val_data/labels.cache... 386 images, 0 backgrounds, 0 corrupt: 100% 386/386 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.4GB ram): 100% 386/386 [00:01<00:00, 215.46it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.36 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
            "Plotting labels to runs/train/exp4/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp4\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/49      3.46G     0.1005    0.02603          0          7        640: 100% 58/58 [00:18<00:00,  3.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.95it/s]\n",
            "                   all        386        386     0.0027      0.811     0.0273      0.008\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/49      4.27G    0.07484    0.02299          0          8        640: 100% 58/58 [00:13<00:00,  4.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.56it/s]\n",
            "                   all        386        386      0.198      0.127     0.0753     0.0228\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/49      4.27G    0.06954    0.02236          0         11        640: 100% 58/58 [00:15<00:00,  3.79it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  3.01it/s]\n",
            "                   all        386        386     0.0988     0.0155     0.0314    0.00861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/49      4.27G    0.06539    0.02241          0         10        640: 100% 58/58 [00:12<00:00,  4.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.97it/s]\n",
            "                   all        386        386      0.214      0.198      0.118     0.0438\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/49      4.27G    0.05965    0.02199          0          5        640: 100% 58/58 [00:14<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.71it/s]\n",
            "                   all        386        386      0.313      0.246      0.146     0.0587\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/49      4.27G    0.06034    0.02174          0         11        640: 100% 58/58 [00:14<00:00,  4.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.91it/s]\n",
            "                   all        386        386      0.215      0.303      0.135     0.0528\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/49      4.27G    0.05529    0.02166          0          4        640: 100% 58/58 [00:13<00:00,  4.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.97it/s]\n",
            "                   all        386        386      0.288      0.275      0.178     0.0668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/49      4.27G    0.05646    0.02111          0          7        640: 100% 58/58 [00:14<00:00,  4.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.34it/s]\n",
            "                   all        386        386      0.353      0.375      0.261      0.103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/49      4.27G    0.05338    0.02117          0         13        640: 100% 58/58 [00:13<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.80it/s]\n",
            "                   all        386        386      0.385      0.409      0.286      0.124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/49      4.27G    0.05028    0.02057          0          9        640: 100% 58/58 [00:14<00:00,  4.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.75it/s]\n",
            "                   all        386        386      0.311      0.394      0.244      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/49      4.27G    0.04997    0.02064          0          9        640: 100% 58/58 [00:13<00:00,  4.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.84it/s]\n",
            "                   all        386        386      0.391      0.461      0.355      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/49      4.27G    0.04918    0.02069          0          9        640: 100% 58/58 [00:14<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.90it/s]\n",
            "                   all        386        386      0.433      0.484      0.357      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/49      4.27G    0.04664    0.02012          0          5        640: 100% 58/58 [00:14<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.28it/s]\n",
            "                   all        386        386        0.4      0.461      0.339      0.155\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/49      4.27G    0.04719    0.01992          0          6        640: 100% 58/58 [00:13<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.91it/s]\n",
            "                   all        386        386      0.431      0.438      0.381      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/49      4.27G    0.04632    0.01999          0          5        640: 100% 58/58 [00:13<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.62it/s]\n",
            "                   all        386        386      0.399      0.451      0.342      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/49      4.27G    0.04681    0.01973          0          6        640: 100% 58/58 [00:14<00:00,  4.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.94it/s]\n",
            "                   all        386        386      0.415      0.339      0.338      0.169\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/49      4.27G    0.04581    0.01991          0         12        640: 100% 58/58 [00:13<00:00,  4.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.90it/s]\n",
            "                   all        386        386      0.396      0.466      0.342      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/49      4.27G    0.04572    0.01961          0          5        640: 100% 58/58 [00:13<00:00,  4.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  3.22it/s]\n",
            "                   all        386        386      0.417      0.503      0.408      0.202\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/49      4.27G     0.0434    0.01993          0          8        640: 100% 58/58 [00:12<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.84it/s]\n",
            "                   all        386        386      0.461      0.508       0.44      0.216\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/49      4.27G    0.04265    0.01929          0          9        640: 100% 58/58 [00:13<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.68it/s]\n",
            "                   all        386        386      0.521      0.475      0.435      0.206\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/49      4.27G    0.04348    0.01966          0          9        640: 100% 58/58 [00:13<00:00,  4.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.84it/s]\n",
            "                   all        386        386      0.482      0.541      0.448      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/49      4.27G    0.04389    0.01931          0          8        640: 100% 58/58 [00:13<00:00,  4.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.95it/s]\n",
            "                   all        386        386       0.49      0.508      0.467      0.229\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/49      4.27G    0.04204    0.01961          0          9        640: 100% 58/58 [00:14<00:00,  4.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.48it/s]\n",
            "                   all        386        386      0.402      0.455      0.411      0.214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/49      4.27G    0.04163    0.01885          0          4        640: 100% 58/58 [00:12<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.85it/s]\n",
            "                   all        386        386       0.41      0.521      0.424      0.217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/49      4.27G    0.04118    0.01882          0         10        640: 100% 58/58 [00:13<00:00,  4.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  3.25it/s]\n",
            "                   all        386        386      0.519      0.552      0.523       0.26\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/49      4.27G    0.04104     0.0189          0          6        640: 100% 58/58 [00:13<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.86it/s]\n",
            "                   all        386        386      0.528      0.514       0.48      0.246\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/49      4.27G    0.04007    0.01904          0          7        640: 100% 58/58 [00:13<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.82it/s]\n",
            "                   all        386        386      0.505      0.549      0.497      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/49      4.27G    0.04124     0.0189          0         11        640: 100% 58/58 [00:13<00:00,  4.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  4.00it/s]\n",
            "                   all        386        386      0.556      0.554       0.51      0.247\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/49      4.27G    0.04022    0.01822          0          8        640: 100% 58/58 [00:13<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.29it/s]\n",
            "                   all        386        386       0.58      0.537      0.534      0.251\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/49      4.27G    0.03939     0.0183          0          8        640: 100% 58/58 [00:12<00:00,  4.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.91it/s]\n",
            "                   all        386        386      0.492       0.56      0.482      0.239\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/49      4.27G    0.03962    0.01868          0          8        640: 100% 58/58 [00:13<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.60it/s]\n",
            "                   all        386        386      0.559      0.601      0.554      0.274\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/49      4.27G    0.03913     0.0182          0          9        640: 100% 58/58 [00:14<00:00,  4.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.93it/s]\n",
            "                   all        386        386      0.482      0.552      0.497      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/49      4.27G    0.03948    0.01793          0          8        640: 100% 58/58 [00:13<00:00,  4.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.87it/s]\n",
            "                   all        386        386      0.561      0.622      0.584      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/49      4.27G    0.03795     0.0188          0          8        640: 100% 58/58 [00:14<00:00,  4.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.49it/s]\n",
            "                   all        386        386      0.546      0.588      0.532      0.277\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/49      4.27G    0.03846    0.01834          0          7        640: 100% 58/58 [00:13<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.83it/s]\n",
            "                   all        386        386      0.572      0.622      0.571      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/49      4.27G    0.03772    0.01745          0         10        640: 100% 58/58 [00:13<00:00,  4.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.43it/s]\n",
            "                   all        386        386        0.5       0.58      0.544      0.288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/49      4.27G    0.03807    0.01737          0          8        640: 100% 58/58 [00:13<00:00,  4.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.93it/s]\n",
            "                   all        386        386      0.642      0.552       0.57      0.297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/49      4.27G    0.03681    0.01753          0          7        640: 100% 58/58 [00:13<00:00,  4.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.63it/s]\n",
            "                   all        386        386       0.52      0.563       0.55      0.297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/49      4.27G    0.03754    0.01757          0          5        640: 100% 58/58 [00:13<00:00,  4.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.62it/s]\n",
            "                   all        386        386      0.535      0.591       0.57      0.315\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/49      4.27G    0.03546    0.01745          0          7        640: 100% 58/58 [00:13<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.85it/s]\n",
            "                   all        386        386      0.565      0.614      0.572        0.3\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/49      4.27G    0.03431    0.01771          0          6        640: 100% 58/58 [00:12<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  3.09it/s]\n",
            "                   all        386        386      0.621      0.609      0.606      0.328\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/49      4.27G    0.03532    0.01765          0         10        640: 100% 58/58 [00:13<00:00,  4.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.83it/s]\n",
            "                   all        386        386      0.582      0.562      0.568      0.301\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/49      4.27G    0.03542     0.0182          0         11        640: 100% 58/58 [00:14<00:00,  4.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.92it/s]\n",
            "                   all        386        386      0.627      0.619      0.622      0.333\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/49      4.27G    0.03516    0.01738          0          4        640: 100% 58/58 [00:14<00:00,  4.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.88it/s]\n",
            "                   all        386        386      0.643      0.611      0.619      0.326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/49      4.27G    0.03547     0.0174          0          9        640: 100% 58/58 [00:13<00:00,  4.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.95it/s]\n",
            "                   all        386        386      0.615      0.596      0.601      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/49      4.27G    0.03391    0.01644          0          6        640: 100% 58/58 [00:13<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  3.20it/s]\n",
            "                   all        386        386      0.601      0.604      0.587      0.326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/49      4.27G    0.03393    0.01711          0          8        640: 100% 58/58 [00:13<00:00,  4.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.83it/s]\n",
            "                   all        386        386      0.648      0.596      0.619      0.343\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/49      4.27G    0.03259    0.01774          0          8        640: 100% 58/58 [00:13<00:00,  4.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.97it/s]\n",
            "                   all        386        386      0.625      0.614       0.62      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/49      4.27G    0.03223    0.01661          0          8        640: 100% 58/58 [00:13<00:00,  4.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.84it/s]\n",
            "                   all        386        386      0.696      0.591       0.65       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/49      4.27G     0.0331    0.01715          0          5        640: 100% 58/58 [00:14<00:00,  4.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.34it/s]\n",
            "                   all        386        386      0.656      0.564      0.632      0.348\n",
            "\n",
            "50 epochs completed in 0.252 hours.\n",
            "Optimizer stripped from runs/train/exp4/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp4/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp4/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.17it/s]\n",
            "                   all        386        386      0.697      0.595       0.65       0.36\n",
            "Results saved to \u001b[1mruns/train/exp4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --source test_dir/images --weights /content/yolov5/runs/train/exp4/weights/best.pt --save-txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPD9EAEDvAcn",
        "outputId": "1c0db119-7bd1-4db4-91c8-0c53881b4917"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp4/weights/best.pt'], source=test_dir/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5  v7.0-226-gdd9e338 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/65 /content/yolov5/test_dir/images/img- (1030).png: 640x640 1 bleeding, 11.5ms\n",
            "image 2/65 /content/yolov5/test_dir/images/img- (107).png: 640x640 (no detections), 11.5ms\n",
            "image 3/65 /content/yolov5/test_dir/images/img- (1075).png: 640x640 1 bleeding, 11.5ms\n",
            "image 4/65 /content/yolov5/test_dir/images/img- (1081).png: 640x640 1 bleeding, 11.5ms\n",
            "image 5/65 /content/yolov5/test_dir/images/img- (1128).png: 640x640 1 bleeding, 11.5ms\n",
            "image 6/65 /content/yolov5/test_dir/images/img- (1164).png: 640x640 1 bleeding, 11.5ms\n",
            "image 7/65 /content/yolov5/test_dir/images/img- (1189).png: 640x640 (no detections), 11.5ms\n",
            "image 8/65 /content/yolov5/test_dir/images/img- (1228).png: 640x640 1 bleeding, 11.5ms\n",
            "image 9/65 /content/yolov5/test_dir/images/img- (1237).png: 640x640 (no detections), 11.5ms\n",
            "image 10/65 /content/yolov5/test_dir/images/img- (1272).png: 640x640 1 bleeding, 11.5ms\n",
            "image 11/65 /content/yolov5/test_dir/images/img- (1287).png: 640x640 (no detections), 11.5ms\n",
            "image 12/65 /content/yolov5/test_dir/images/img- (1299).png: 640x640 (no detections), 11.5ms\n",
            "image 13/65 /content/yolov5/test_dir/images/img- (13).png: 640x640 (no detections), 11.5ms\n",
            "image 14/65 /content/yolov5/test_dir/images/img- (1309).png: 640x640 1 bleeding, 8.6ms\n",
            "image 15/65 /content/yolov5/test_dir/images/img- (134).png: 640x640 1 bleeding, 8.4ms\n",
            "image 16/65 /content/yolov5/test_dir/images/img- (138).png: 640x640 1 bleeding, 8.3ms\n",
            "image 17/65 /content/yolov5/test_dir/images/img- (142).png: 640x640 1 bleeding, 8.4ms\n",
            "image 18/65 /content/yolov5/test_dir/images/img- (170).png: 640x640 (no detections), 8.3ms\n",
            "image 19/65 /content/yolov5/test_dir/images/img- (178).png: 640x640 (no detections), 8.3ms\n",
            "image 20/65 /content/yolov5/test_dir/images/img- (198).png: 640x640 (no detections), 8.3ms\n",
            "image 21/65 /content/yolov5/test_dir/images/img- (22).png: 640x640 (no detections), 8.3ms\n",
            "image 22/65 /content/yolov5/test_dir/images/img- (235).png: 640x640 1 bleeding, 8.4ms\n",
            "image 23/65 /content/yolov5/test_dir/images/img- (245).png: 640x640 (no detections), 8.4ms\n",
            "image 24/65 /content/yolov5/test_dir/images/img- (256).png: 640x640 1 bleeding, 9.1ms\n",
            "image 25/65 /content/yolov5/test_dir/images/img- (265).png: 640x640 1 bleeding, 8.3ms\n",
            "image 26/65 /content/yolov5/test_dir/images/img- (287).png: 640x640 1 bleeding, 7.0ms\n",
            "image 27/65 /content/yolov5/test_dir/images/img- (357).png: 640x640 1 bleeding, 7.0ms\n",
            "image 28/65 /content/yolov5/test_dir/images/img- (364).png: 640x640 1 bleeding, 7.0ms\n",
            "image 29/65 /content/yolov5/test_dir/images/img- (367).png: 640x640 1 bleeding, 7.0ms\n",
            "image 30/65 /content/yolov5/test_dir/images/img- (383).png: 640x640 (no detections), 7.0ms\n",
            "image 31/65 /content/yolov5/test_dir/images/img- (398).png: 640x640 1 bleeding, 7.0ms\n",
            "image 32/65 /content/yolov5/test_dir/images/img- (419).png: 640x640 1 bleeding, 7.0ms\n",
            "image 33/65 /content/yolov5/test_dir/images/img- (429).png: 640x640 (no detections), 6.8ms\n",
            "image 34/65 /content/yolov5/test_dir/images/img- (43).png: 640x640 1 bleeding, 6.8ms\n",
            "image 35/65 /content/yolov5/test_dir/images/img- (443).png: 640x640 1 bleeding, 6.8ms\n",
            "image 36/65 /content/yolov5/test_dir/images/img- (450).png: 640x640 1 bleeding, 6.8ms\n",
            "image 37/65 /content/yolov5/test_dir/images/img- (46).png: 640x640 2 bleedings, 6.8ms\n",
            "image 38/65 /content/yolov5/test_dir/images/img- (461).png: 640x640 1 bleeding, 6.8ms\n",
            "image 39/65 /content/yolov5/test_dir/images/img- (479).png: 640x640 1 bleeding, 6.3ms\n",
            "image 40/65 /content/yolov5/test_dir/images/img- (480).png: 640x640 1 bleeding, 6.3ms\n",
            "image 41/65 /content/yolov5/test_dir/images/img- (516).png: 640x640 (no detections), 6.3ms\n",
            "image 42/65 /content/yolov5/test_dir/images/img- (590).png: 640x640 1 bleeding, 6.3ms\n",
            "image 43/65 /content/yolov5/test_dir/images/img- (605).png: 640x640 1 bleeding, 6.3ms\n",
            "image 44/65 /content/yolov5/test_dir/images/img- (616).png: 640x640 1 bleeding, 6.3ms\n",
            "image 45/65 /content/yolov5/test_dir/images/img- (620).png: 640x640 (no detections), 6.2ms\n",
            "image 46/65 /content/yolov5/test_dir/images/img- (647).png: 640x640 (no detections), 6.2ms\n",
            "image 47/65 /content/yolov5/test_dir/images/img- (651).png: 640x640 1 bleeding, 6.1ms\n",
            "image 48/65 /content/yolov5/test_dir/images/img- (654).png: 640x640 1 bleeding, 6.1ms\n",
            "image 49/65 /content/yolov5/test_dir/images/img- (663).png: 640x640 (no detections), 6.2ms\n",
            "image 50/65 /content/yolov5/test_dir/images/img- (70).png: 640x640 1 bleeding, 6.2ms\n",
            "image 51/65 /content/yolov5/test_dir/images/img- (704).png: 640x640 1 bleeding, 6.1ms\n",
            "image 52/65 /content/yolov5/test_dir/images/img- (724).png: 640x640 1 bleeding, 6.0ms\n",
            "image 53/65 /content/yolov5/test_dir/images/img- (786).png: 640x640 (no detections), 5.9ms\n",
            "image 54/65 /content/yolov5/test_dir/images/img- (809).png: 640x640 (no detections), 6.0ms\n",
            "image 55/65 /content/yolov5/test_dir/images/img- (818).png: 640x640 1 bleeding, 5.9ms\n",
            "image 56/65 /content/yolov5/test_dir/images/img- (835).png: 640x640 1 bleeding, 6.0ms\n",
            "image 57/65 /content/yolov5/test_dir/images/img- (844).png: 640x640 1 bleeding, 5.9ms\n",
            "image 58/65 /content/yolov5/test_dir/images/img- (854).png: 640x640 1 bleeding, 5.9ms\n",
            "image 59/65 /content/yolov5/test_dir/images/img- (861).png: 640x640 1 bleeding, 5.9ms\n",
            "image 60/65 /content/yolov5/test_dir/images/img- (88).png: 640x640 1 bleeding, 5.9ms\n",
            "image 61/65 /content/yolov5/test_dir/images/img- (933).png: 640x640 1 bleeding, 5.9ms\n",
            "image 62/65 /content/yolov5/test_dir/images/img- (966).png: 640x640 1 bleeding, 5.9ms\n",
            "image 63/65 /content/yolov5/test_dir/images/img- (971).png: 640x640 (no detections), 5.9ms\n",
            "image 64/65 /content/yolov5/test_dir/images/img- (99).png: 640x640 (no detections), 5.9ms\n",
            "image 65/65 /content/yolov5/test_dir/images/img- (993).png: 640x640 (no detections), 5.9ms\n",
            "Speed: 0.5ms pre-process, 7.8ms inference, 2.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp5\u001b[0m\n",
            "43 labels saved to runs/detect/exp5/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "iou_values=[]\n",
        "exp='exp5'\n",
        "# Function to parse YOLO bounding box format\n",
        "def parse_yolo_box(yolo_box_str):\n",
        "    values = yolo_box_str.strip().split()\n",
        "    class_id = int(values[0])\n",
        "    x_center, y_center, width, height = map(float, values[1:])\n",
        "    return class_id, x_center, y_center, width, height\n",
        "\n",
        "# Function to calculate IoU\n",
        "def calculate_iou(box1, box2):\n",
        "    x1, y1, w1, h1 = box1\n",
        "    x2, y2, w2, h2 = box2\n",
        "\n",
        "    x_intersection = max(x1 - w1 / 2, x2 - w2 / 2)\n",
        "    y_intersection = max(y1 - h1 / 2, y2 - h2 / 2)\n",
        "    w_intersection = min(x1 + w1 / 2, x2 + w2 / 2) - x_intersection\n",
        "    h_intersection = min(y1 + h1 / 2, y2 + h2 / 2) - y_intersection\n",
        "\n",
        "    if w_intersection <= 0 or h_intersection <= 0:\n",
        "        return 0.0\n",
        "\n",
        "    area_intersection = w_intersection * h_intersection\n",
        "    area_box1 = w1 * h1\n",
        "    area_box2 = w2 * h2\n",
        "\n",
        "    iou = area_intersection / (area_box1 + area_box2 - area_intersection)\n",
        "    return iou\n",
        "\n",
        "# Folder paths for predicted and ground truth label text files\n",
        "predicted_folder = '/content/yolov5/runs/detect/'+exp+'/labels'\n",
        "ground_truth_folder = '/content/yolov5/test_dir/labels'\n",
        "\n",
        "# Iterate through files in the predicted folder\n",
        "for filename in os.listdir(ground_truth_folder):\n",
        "    if filename.endswith('.txt'):\n",
        "        predicted_filepath = os.path.join(predicted_folder, filename)\n",
        "        ground_truth_filepath = os.path.join(ground_truth_folder, filename)\n",
        "\n",
        "        # Check if the corresponding ground truth file exists\n",
        "        if not os.path.exists(predicted_filepath):\n",
        "            print(f\"No detections in {filename}\")\n",
        "            iou_values.append(0)\n",
        "            continue\n",
        "\n",
        "        with open(predicted_filepath, 'r') as predicted_file, open(ground_truth_filepath, 'r') as ground_truth_file:\n",
        "            predicted_lines = predicted_file.readlines()\n",
        "            ground_truth_lines = ground_truth_file.readlines()\n",
        "\n",
        "            # Ensure the same number of lines in both files\n",
        "            if len(predicted_lines) != len(ground_truth_lines):\n",
        "                print(f\"Error: Number of boxes in {filename} doesn't match.\")\n",
        "                continue\n",
        "\n",
        "            # Parse and compare each pair of boxes\n",
        "            for predicted_line, ground_truth_line in zip(predicted_lines, ground_truth_lines):\n",
        "                predicted_box = parse_yolo_box(predicted_line)\n",
        "                ground_truth_box = parse_yolo_box(ground_truth_line)\n",
        "\n",
        "                # Calculate IoU for the pair of boxes\n",
        "                iou = calculate_iou(predicted_box[1:], ground_truth_box[1:])\n",
        "                iou_values.append(iou)\n",
        "                print(f\"IoU for {filename}: {iou}\")\n",
        "\n",
        "# You can further process the IoU values as needed (e.g., calculate metrics)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFWCY_ofvm06",
        "outputId": "b8ebfe5b-f8f3-4c5b-f6fb-f895cb2fa187"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IoU for img- (651).txt: 0.4887215639039998\n",
            "No detections in img- (245).txt\n",
            "IoU for img- (256).txt: 0.3020930666150698\n",
            "No detections in img- (170).txt\n",
            "IoU for img- (1272).txt: 0.17170503363224637\n",
            "IoU for img- (364).txt: 0.22442410019318484\n",
            "IoU for img- (1164).txt: 0.8985126134729132\n",
            "IoU for img- (70).txt: 0.0\n",
            "IoU for img- (367).txt: 0.8336401131780031\n",
            "No detections in img- (647).txt\n",
            "IoU for img- (818).txt: 0.8461522297746691\n",
            "No detections in img- (786).txt\n",
            "No detections in img- (383).txt\n",
            "IoU for img- (134).txt: 0.8389922283504508\n",
            "IoU for img- (724).txt: 0.879915062040954\n",
            "No detections in img- (107).txt\n",
            "IoU for img- (590).txt: 0.8141083670439749\n",
            "No detections in img- (1237).txt\n",
            "No detections in img- (22).txt\n",
            "IoU for img- (450).txt: 0.0\n",
            "No detections in img- (809).txt\n",
            "IoU for img- (480).txt: 0.9195305070161925\n",
            "IoU for img- (1228).txt: 0.4540826032030231\n",
            "IoU for img- (88).txt: 0.888862774259415\n",
            "No detections in img- (1189).txt\n",
            "IoU for img- (43).txt: 0.8427700721028091\n",
            "IoU for img- (419).txt: 0.8973093576255655\n",
            "IoU for img- (605).txt: 0.8867193146283636\n",
            "IoU for img- (854).txt: 0.6702229272647428\n",
            "Error: Number of boxes in img- (46).txt doesn't match.\n",
            "IoU for img- (966).txt: 0.7744455764918107\n",
            "IoU for img- (861).txt: 0.8543766901338606\n",
            "No detections in img- (663).txt\n",
            "IoU for img- (357).txt: 0.5587802739045737\n",
            "No detections in img- (198).txt\n",
            "IoU for img- (1030).txt: 0.8986759481973895\n",
            "No detections in img- (516).txt\n",
            "No detections in img- (99).txt\n",
            "IoU for img- (142).txt: 0.18565599007784397\n",
            "IoU for img- (616).txt: 0.6471869116873182\n",
            "No detections in img- (620).txt\n",
            "No detections in img- (178).txt\n",
            "IoU for img- (398).txt: 0.5429906567833568\n",
            "IoU for img- (1309).txt: 0.388947307628241\n",
            "No detections in img- (971).txt\n",
            "IoU for img- (235).txt: 0.41706318516854185\n",
            "No detections in img- (1299).txt\n",
            "IoU for img- (1081).txt: 0.7939214703591779\n",
            "IoU for img- (265).txt: 0.8939131321895496\n",
            "IoU for img- (138).txt: 0.5206830464620292\n",
            "No detections in img- (993).txt\n",
            "IoU for img- (1075).txt: 0.7994666170721157\n",
            "No detections in img- (429).txt\n",
            "IoU for img- (654).txt: 0.7928590457188525\n",
            "IoU for img- (443).txt: 0.0\n",
            "IoU for img- (704).txt: 0.8335288598813799\n",
            "IoU for img- (287).txt: 0.17312898496141543\n",
            "IoU for img- (844).txt: 0.6492270380965791\n",
            "IoU for img- (1128).txt: 0.0\n",
            "IoU for img- (835).txt: 0.7535708515351534\n",
            "No detections in img- (13).txt\n",
            "No detections in img- (1287).txt\n",
            "IoU for img- (479).txt: 0.967585210232047\n",
            "IoU for img- (461).txt: 0.8085242446032394\n",
            "IoU for img- (933).txt: 0.43574048695204426\n"
          ]
        }
      ]
    }
  ]
}